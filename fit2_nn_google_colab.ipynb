{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fit2_nn_google_colab.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIYYs96gifDn",
        "outputId": "d22b8037-edf2-4cb2-96da-b7ee8b7355fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DIR = 'drive/MyDrive/sber'\n",
        "\n",
        "TRAIN_VAL2_PATH = os.path.join(DIR, 'train_val2.parquet') \n",
        "VAL2_PATH = os.path.join(DIR, 'val2.parquet')  \n",
        "\n",
        "TRAIN_VAL1_PATH = os.path.join(DIR, 'train_val1.parquet') \n",
        "VAL1_PATH = os.path.join(DIR, 'val1.parquet')  \n",
        "RECS_NN_VAL1_PATH = os.path.join(DIR, 'recs_nn_val1.parquet') \n",
        "\n",
        "USER_DECODER_PATH = os.path.join(DIR, 'user_decoder.pkl') \n",
        "NN_MODEL_PATH = os.path.join(DIR, 'nn_model.pkl')\n",
        "\n",
        "NUM_CLUSTERS = 8000\n",
        "NUM_USERS = 1595239\n",
        "NUM_RETAILERS = 118\n",
        "NUM_CITIES = 148"
      ],
      "metadata": {
        "id": "vxm1p0AcilT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable, List\n",
        "\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "VIjZ_nCTilWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparse_matrix(short_train, col, num_classes, use_ones=False):\n",
        "  df = short_train[['user_id', col]].drop_duplicates()\n",
        "  df[f'user_{col}'] = df['user_id'].astype(np.int64) * 10000 + df[col]\n",
        "  df['user_col_count'] = df[f'user_{col}'].map(short_train[f'user_{col}'].value_counts()) \n",
        "  df['user_count'] = df['user_id'].map(short_train['user_id'].value_counts()) \n",
        "  df['user_col_share'] = df['user_col_count'] / df['user_count']\n",
        "  if use_ones:\n",
        "    return sp.csr_matrix((np.ones(len(df)), (df['user_id'], df[col])), shape=(NUM_USERS, num_classes))\n",
        "  return sp.csr_matrix((df['user_col_share'], (df['user_id'], df[col])), shape=(NUM_USERS, num_classes))\n",
        "\n",
        "def create_x_y(train_val, val=None):\n",
        "  short_train = train_val[~train_val[['order_id', 'cluster_id']].duplicated()]\n",
        "  short_train['user_retailer_id'] = short_train['user_id'].astype(np.int64) * 10000 + short_train['retailer_id']\n",
        "  short_train['user_city_id'] = short_train['user_id'].astype(np.int64) * 10000 + short_train['city_id']\n",
        "  short_train['user_cluster_id'] = short_train['user_id'].astype(np.int64) * 10000 + short_train['cluster_id']\n",
        "\n",
        "  x1 = create_sparse_matrix(short_train, 'retailer_id', NUM_RETAILERS)\n",
        "  x2 = create_sparse_matrix(short_train, 'city_id', NUM_CITIES)\n",
        "  x3 = create_sparse_matrix(short_train, 'cluster_id', NUM_CLUSTERS)\n",
        "  x4 = create_sparse_matrix(short_train, 'cluster_id', NUM_CLUSTERS, True)\n",
        "\n",
        "  x = sp.hstack([x1, x2, x3, x4], format='csr')\n",
        "  if val is not None:\n",
        "    y = sp.csr_matrix((np.ones(len(val)), [val['user_id'], val['cluster_id']]), shape=(NUM_USERS, NUM_CLUSTERS))\n",
        "    return x, y\n",
        "  else:\n",
        "    return x, None\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    \n",
        "    def __init__(self, x, y, users, batch_size, device='cuda'):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.users = users\n",
        "        self.num_users = len(users)\n",
        "        self.num_batches = int((self.num_users - 1) / batch_size + 1)\n",
        "        \n",
        "    def __getitem__(self, batch_num):\n",
        "        \n",
        "        i = batch_num * self.batch_size\n",
        "        size = min(self.num_users - i, self.batch_size)\n",
        "        users = self.users[i: i + size]\n",
        "        if y is not None:\n",
        "          return (torch.FloatTensor(self.x[users].todense()).to(self.device), \n",
        "                  torch.FloatTensor(self.y[users].todense()).to(self.device))\n",
        "        else:\n",
        "          return torch.FloatTensor(self.x[users].todense()).to(self.device), None\n",
        "            \n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.users)\n",
        "        for i in range(self.num_batches):\n",
        "            yield self[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        dim = 2 * NUM_CLUSTERS + NUM_RETAILERS + NUM_CITIES\n",
        "        self.linear = torch.nn.Linear(dim, 10000).to(self.device)\n",
        "        self.linear2 = torch.nn.Linear(10000, NUM_CLUSTERS).to(self.device)\n",
        "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear2(self.relu(self.linear(x))))\n",
        "\n",
        "\n",
        "def fit_model(model, dataset):\n",
        "  optimizer = torch.optim.Adagrad(model.parameters(), lr=config['lr'])\n",
        "  loss_function = torch.nn.BCELoss()\n",
        "  for epoch in range(config['epoch']):\n",
        "      for x, y in dataset:\n",
        "          optimizer.zero_grad()\n",
        "          score = model(x)\n",
        "          loss = loss_function(score, y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "def get_rec(model, dataset, topk=160):\n",
        "  items = []\n",
        "  scores = []\n",
        "  losses = []\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataset:\n",
        "      score = model(x)\n",
        "      recom = torch.topk(score, topk)\n",
        "      items.append(recom[1].flatten().cpu().detach().numpy().astype(np.int16))\n",
        "      scores.append(recom[0].flatten().cpu().detach().numpy())\n",
        "\n",
        "  users = dataset.users.reshape(-1, 1).repeat(topk, 1).flatten()\n",
        "  items = np.hstack(items)\n",
        "  scores = np.hstack(scores)\n",
        "\n",
        "  recs = pd.DataFrame()\n",
        "  recs['user_id'] = users\n",
        "  recs['cluster_id'] = items\n",
        "  recs['scores'] = scores\n",
        "  return recs"
      ],
      "metadata": {
        "id": "ebcaxeNmjCpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 3000,\n",
        "    'device': 'cuda',\n",
        "    'lr': 0.01,\n",
        "    'epoch': 10,\n",
        "}"
      ],
      "metadata": {
        "id": "8WafVaL9jSfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val2 =  pd.read_parquet(TRAIN_VAL2_PATH)\n",
        "val2 = pd.read_parquet(VAL2_PATH)\n",
        "x, y = create_x_y(train_val2, val2)\n",
        "dataset = Dataset(x, y, val2['user_id'].unique(), config['batch_size'], config['device'])\n",
        "model = Model(config['device'])\n",
        "fit_model(model, dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9n_-vKCjSiz",
        "outputId": "082ccf20-a77a-4022-ecba-c05d83cc3ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val1 =  pd.read_parquet(TRAIN_VAL1_PATH)\n",
        "val1 = pd.read_parquet(VAL1_PATH)\n",
        "x, y = create_x_y(train_val1, val1)\n",
        "dataset = Dataset(x, y, val1['user_id'].unique(), config['batch_size'], config['device'])\n",
        "recs = get_rec(model, dataset)\n",
        "recs.to_parquet(RECS_NN_VAL1_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0_y2kHMjWZQ",
        "outputId": "97b8e966-77a3-4539-c7a3-df70bfd18944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(config['device'])\n",
        "fit_model(model, dataset)\n",
        "model.cpu()\n",
        "model.device = 'cpu'\n",
        "pickle.dump(model, open(NN_MODEL_PATH, 'wb'))"
      ],
      "metadata": {
        "id": "MmyiE0I5jWcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nwSsoK2C9iml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}